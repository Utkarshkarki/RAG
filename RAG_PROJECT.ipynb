{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvwMAGEY7iKiNoP8Z5mCEg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Utkarshkarki/RAG/blob/main/RAG_PROJECT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CukfvDLHSRDw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbb17c30-0848-4f10-edd6-2da2f34e7c13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Running in Google Colab,installing requirements.\n",
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.26.4\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.10.1)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.34.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate) (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.8.3)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.47.0\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.8.3.tar.gz (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from flash-attn) (2.8.0+cu126)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from flash-attn) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->flash-attn) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.8.3-cp312-cp312-linux_x86_64.whl size=256040057 sha256=f25da18657a87fc83dc1bfb8b7751b82246e9db355510226b674fd437c34b5fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/59/46/f282c12c73dd4bb3c2e3fe199f1a0d0f8cec06df0cccfeee27\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: flash-attn\n",
            "Successfully installed flash-attn-2.8.3\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "if \"COLAB_GPU\" in os.environ:\n",
        "  print(\"[INFO] Running in Google Colab,installing requirements.\")\n",
        "  !pip install PyMuPDF\n",
        "  !pip install tqdm\n",
        "  !pip install accelerate\n",
        "  !pip install bitsandbytes\n",
        "  !pip install flash-attn --no-build-isolation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torch torchvision torchaudio transformers sentence-transformers\n",
        "!pip install torch toechvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install -U transformers sentence-transformers"
      ],
      "metadata": {
        "id": "wytciCmdTBjw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25145730-f22d-40ac-f13e-66c76304a145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.8.0+cu126\n",
            "Uninstalling torch-2.8.0+cu126:\n",
            "  Successfully uninstalled torch-2.8.0+cu126\n",
            "Found existing installation: torchvision 0.23.0+cu126\n",
            "Uninstalling torchvision-0.23.0+cu126:\n",
            "  Successfully uninstalled torchvision-0.23.0+cu126\n",
            "Found existing installation: torchaudio 2.8.0+cu126\n",
            "Uninstalling torchaudio-2.8.0+cu126:\n",
            "  Successfully uninstalled torchaudio-2.8.0+cu126\n",
            "Found existing installation: transformers 4.56.1\n",
            "Uninstalling transformers-4.56.1:\n",
            "  Successfully uninstalled transformers-4.56.1\n",
            "Found existing installation: sentence-transformers 5.1.0\n",
            "Uninstalling sentence-transformers-5.1.0:\n",
            "  Successfully uninstalled sentence-transformers-5.1.0\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp312-cp312-linux_x86_64.whl (780.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.4/780.4 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement toechvision (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for toechvision\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting transformers\n",
            "  Downloading transformers-4.56.2-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m810.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence-transformers\n",
            "  Downloading sentence_transformers-5.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Collecting torch>=1.11.0 (from sentence-transformers)\n",
            "  Downloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Downloading transformers-4.56.2-py3-none-any.whl (11.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentence_transformers-5.1.0-py3-none-any.whl (483 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m483.4/483.4 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.8.0-cp312-cp312-manylinux_2_28_x86_64.whl (887.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.9/887.9 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cusolver-cu12, transformers, torch, sentence-transformers\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufile-cu12\n",
            "    Found existing installation: nvidia-cufile-cu12 1.11.1.6\n",
            "    Uninstalling nvidia-cufile-cu12-1.11.1.6:\n",
            "      Successfully uninstalled nvidia-cufile-cu12-1.11.1.6\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "pdf_path =\"human-nutrition-text.pdf\"\n",
        "\n",
        "if not os.path.exists(pdf_path):\n",
        "  print(\"File doesn't exist, downloading....\")\n",
        "\n",
        "  #The URL of the pdf you want to download\n",
        "  url=\n",
        "\n",
        "  filename = pdf_path\n",
        "\n",
        "  response  = requests.get(url)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "     with open(filename,\"wb\") as file:\n",
        "        file.write(response.content)\n",
        "      print(f\"The file has been downloaded and saved as {filename}\")\n",
        "  else:\n",
        "    print(f\"Failed to download the file. Status code:{response.status_code}\")\n",
        "else:\n",
        "  print{f\"File {pdf_path} exists.\"}\n"
      ],
      "metadata": {
        "id": "wgwC8ItkTlBo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "bbacda11-34d1-4777-bf11-661f5f6032bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 19)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    print(f\"The file has been downloaded and saved as {filename}\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def text_formatter(text: str) -> str:\n",
        "  \"\"\"Perform minor formatting on text.\"\"\"\"\n",
        "   cleaned_text = text.replace(\"\\n\",\" \").strip()\n",
        "\n",
        "   return cleaned_text\n",
        "\n",
        "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
        "  doc  = fitz.open(pdf_path)\n",
        "  pages_and_texts = []\n",
        "  for page_number , page in tqdm(enumerate(doc)):\n",
        "    text = page.get_text()\n",
        "    text = text_formatter(text)\n",
        "    pages_and_texts.append({\"page_number\": page_number - 41,\"page_char_count\": len(text),\n",
        "                            \"page_word_count\": len(text.split(\" \")),\n",
        "                            \"page_sentence_count_raw\": len(text.split(\". \")),\n",
        "                            \"page_token_count\": len(text) / 4,\n",
        "                            \"text\": text})\n",
        "    return pages_and_texts\n",
        "\n",
        "pages_and_texts = open_and_read_pdf(pdf_path=pdf_path)\n",
        "pages_and_texts[:2]\n"
      ],
      "metadata": {
        "id": "epiolzxCTlEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.sample(pages_and_texts, k=3)"
      ],
      "metadata": {
        "id": "xsIV9yD8TlG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(pages_and_texts)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "DA9CU--pTlJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().round(2)"
      ],
      "metadata": {
        "id": "U11HAGI_TlLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en import English\n",
        "nlp=English()\n",
        "nlp.add_pipe(\"sentencizer\")\n",
        "#create a document instance as an example\n",
        "doc=nlp(\"This is a sentence.This another sentence\")\n",
        "assert len(list(doc.sents))==2\n",
        "\n",
        "#Access the sentences of the document\n",
        "list(doc.sents)"
      ],
      "metadata": {
        "id": "aoqlxz81TlN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in tqdm(pages_and_texts):\n",
        "  item[\"sentences\"]=list(nlp(item[\"text\"]).sents)\n",
        "\n",
        "  #Make sure all sentences are strings\n",
        "  item[\"sentences\"]=[str(sentence) for sentence in item[\"sentences\"]]\n",
        "  #count the sentences\n",
        "  item[\"page_sentences_count_spacy\"]=len(item[\"sentences\"])"
      ],
      "metadata": {
        "id": "4JuJ1eVKTlRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspect an example\n",
        "random.sample(pages_and_texts,k=1)"
      ],
      "metadata": {
        "id": "HK9dk7bwYi2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.dataFrame(pages_and_texts)\n",
        "df.describe().round(2)"
      ],
      "metadata": {
        "id": "0MzrYRt6Yi4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define split size to turn groups of sentences into chunks\n",
        "num_sentence_chunk_size=10\n",
        "\n",
        "#create a function that recursively splits a list into desired sizes\n",
        "def split_list(input_list: list,\n",
        "               slice_size: int)-> list[list[str]]:\n",
        "      \"\"\"\n",
        "      Splits the input_list into sublists of size slice_size (or as close as possible).\n",
        "      For example, a list of 17 sentences would be split into two lists of[[10],[7]]\n",
        "      \"\"\"\n",
        "      return [input_list[i:i + slice_size] for i in range(0,len(input_list),slice_size)]\n",
        "\n",
        "   #Loop through pages and texts and split sentences into chunks\n",
        "\n",
        "   for item in tqdm(pages_and_texts):\n",
        "      item[\"sentence_chunks\"]=split_list(input_list=item[\"sentences\"],\n",
        "                                         slice_size=num_sentence_chunk_size)\n",
        "      item[\"num_chunks\"]=len(item[\"sentence_chunks\"])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D49GgSkSYi7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.sample(pages_and_texts,k=1)"
      ],
      "metadata": {
        "id": "WtKbBliyYi9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a DataFrame to get stats\n",
        "df=pd.dataFrame(pages_and_texts)\n",
        "df.describe().round(2)"
      ],
      "metadata": {
        "id": "3fX_VCSkYjBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define split size to turn groups of sentences into chunks\n",
        "num_sentence_chunk_size=10\n",
        "\n",
        "#Create a function that recursively splits a list into desired sizes\n",
        "def split_list(input_list: list,\n",
        "               slice_size: int)-> list[list[str]]:\n",
        "\n",
        "    \"\"\"\n",
        "    Splits the input input_list into sublists of size slice_size(or as close as possible).\n",
        "\n",
        "    for example, a list of 17 sentences would be split into two lists of [[10],[7]]\n",
        "    \"\"\"\n",
        "    return [input_list[i:i + slice_size] for i in range(0,len(input_list),slice_size)]\n",
        "\n",
        "#Loop through pages and texts and split sentences into chunks\n",
        "for item in tqdm(pages_and_texts):\n",
        "  item[\"sentence_chunks\"]=split_list(input_list=item[\"sentences\"],\n",
        "                                     slice_size=num_sentence_chunk_size)\n",
        "  item[\"num_chunks\"]=len(item[\"sentence_chunks\"])"
      ],
      "metadata": {
        "id": "fI5C6xB0YjD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample an example from the group (note: many samples have only 1 chunk as they have <=10 sentences total)\n",
        "\n",
        "random.sample(pages_and_texts,k=1)"
      ],
      "metadata": {
        "id": "RESaLBLEYjF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a dataframe to get stats\n",
        "df=pd.dataFrame(pages_and_texts)\n",
        "df.describe().round(2)"
      ],
      "metadata": {
        "id": "ZbePdUVcYjIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "#Split each chunk into its own item\n",
        "pages_and_chunks=[]\n",
        "for item in tqdm(pages_and_texts):\n",
        "  for sentence_chunk in item[\"sentence_chunk\"]:\n",
        "    chunk_dict={ }\n",
        "    chunk_dict[\"page_number\"]=item[\"page_number\"]\n",
        "\n",
        "    #join the sentences together into a paragraph-like structure, aka a chunk (so they are a single)\n",
        "    joined_sentence_chunk=\"\".join(sentence_chunk).replace(\"  \",\" \").strip()\n",
        "    joined_sentence_chunk=re.sub(r'\\.([A-Z])',r'.\\1',joined_sentence_chunk)\n",
        "    chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
        "\n",
        "    #Get stats about the chunk\n",
        "    chunk_dict[\"chunk_char_count\"]=len(joined_sentence_chunk)\n",
        "    chunk_dict[\"chunk_word_count\"]=len([word for word in joined_sentence_chunk.split(\" \")])\n",
        "    chunk_dict[\"chunk_token_count\"]=len(joined_sentence_chunk) / 4 #1 token =~4 characters\n",
        "\n",
        "    pages_and_chunks.append(chunk_dict)\n",
        "#How many chunks do we have?\n",
        "len(pages_and_chunks)\n",
        "\n"
      ],
      "metadata": {
        "id": "tn0OF-IMYjLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.sample(pages_and_chunks, k=1)"
      ],
      "metadata": {
        "id": "82K-tBReYjNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get stats about our chunks\n",
        "df=pd.DataFrame(pages_and_chunks)\n",
        "df.describe().round(2)"
      ],
      "metadata": {
        "id": "V9Y1c_dlYjQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show random chunks with under 30 tokens in length\n",
        "min_token_length=36\n",
        "for row in df[df[\"chunk_token_count\"] <= min_token_length].sample(5).iterrows():\n",
        "   print(f'Chunk token count: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"sentence_chunk\"]}')\n"
      ],
      "metadata": {
        "id": "WBLb3p1iYjTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pages_and_chunks_over_min_token_len=df[df[\"chunk_token_count\"] > min_token_length].to_dict(orient=\"records\")\n",
        "pages_and_chunks_over_min_token_len[:2]"
      ],
      "metadata": {
        "id": "1i1LAeFGzSPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "embedding_model=SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\",\n",
        "                                    device=\"cpu\")\n",
        "\n",
        "#create a list of sentences to turn into numbers\n",
        "sentences=[\n",
        "    \"The Sentences Transformers library provides an easy and open-source way to create embeddings.\",\n",
        "    \"Sentence can be embedded one by one or as a list of strings.\",\n",
        "    \"Embeddings are one of the most powerful concepts in machine learning!\",\n",
        "    \"Learn to use embeddings well and you'll be well on your way to being an AI engineer.\"\n",
        "]\n",
        "#Sentences are encoded/embedded by calling model.encode()\n",
        "embeddings=embedding_model.encode(sentences)\n",
        "embeddings_dict=dict(zip(sentences,embeddings))\n",
        "\n",
        "#see the embeddings\n",
        "for sentence,embedding in embeddings_dict.items():\n",
        "  print(\"Sentence:\", sentence)\n",
        "  print(\"Embedding:\",embedding)\n",
        "  print(\"\")\n"
      ],
      "metadata": {
        "id": "d2pwh5KIzSSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "single_sentence=\"Yo! How cool are embeddings?\"\n",
        "single_embedding=embedding_model.encode(single_sentence)\n",
        "print(f\"Sentence:{single_sentence}\")\n",
        "print(f\"Embedding:\\n{single_embedding}\")\n",
        "print(f\"Embedding size:{single_embedding.shape}\")"
      ],
      "metadata": {
        "id": "QJRz0atjzSUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#Uncomment to see how long it takes to create embeddings on CPU\n",
        "# # Make sure the model is on CPU\n",
        "embedding_model.to(\"cpu\")\n",
        "\n",
        "# # Embed each chunk one by  one\n",
        "for item in tqdm(pages_and_chunks_over_min_token_len):\n",
        "  item[\"embedding\"]=embedding_model.encode(item[\"sentence_chunk\"])"
      ],
      "metadata": {
        "id": "kBxPMCZdzSW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#send the model to the GPU\n",
        "embedding_model.to(\"cuda\")\n",
        "\n",
        "#create embeddings one by one on the GPU\n",
        "for item in tqdm(pages_and_chunks_over_min_token_len):\n",
        "  item[\"embedding\"]=embedding_model.encode(item[\"sentence_chunk\"])"
      ],
      "metadata": {
        "id": "rIgYbd4EzSZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Turn text chunks into a single list.\n",
        "text_chunks=[item['sentence_chunk'] for item in pages_and_chunks_over_min_token_len]"
      ],
      "metadata": {
        "id": "iUQKb0D9zSgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#Embed all texts in batches\n",
        "text_chunk_embeddings = embedding_model.encode(text_chunks,batch_size=32,convert_to_tensor=True)\n",
        "text_chunk_embeddings"
      ],
      "metadata": {
        "id": "IxtRsWO8zSjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save embeddings to file\n",
        "text_chunks_and_embeddings_df=pd.DataFrame(pages_and_chunks_over_min_token_len)\n",
        "embeddings_df_save_path=\"text_chunks_and_embeddings_df.csv\"\n",
        "text_chunks_and_embeddings_df.to_csv(embeddings_df_save_path,index=False)"
      ],
      "metadata": {
        "id": "hGxfZmwpSco0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import saved file and view\n",
        "text_chunks_and_embedding_df_load = pd.read_csv(embeddings_df_save_path)\n",
        "text_chunks_and_embedding_df_load.head()"
      ],
      "metadata": {
        "id": "wwW3xaS1Scrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L4JBytzxScum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "#Imports texts and embedding df\n",
        "text_chunks_and_embedding_df=pd.read_csv(\"text_chunks_and_embeddings_df.csv\")\n",
        "\n",
        "#convert embedding column back to np.array (it got converted to string when it got saved to csv)\n",
        "text_chunks_and_embedding_df[\"embedding\"]=text_chunks_and_embedding_df[\"embedding\"].apply(lambda x: np.fromstring(x.strip(\"[]\"),))\n",
        "\n",
        "#Convert texts and embedding df to list of dicts\n",
        "pages_and_chunks = text_chunks_and_embedding_df.to_dict(orient=\"records\")\n",
        "\n",
        "#Convert embeddings to torch tensor and send to device (note: NumPy arrays are float64, torch tensors are float32 by default)\n",
        "embeddings = torch.tensor(np.array(text_chunks_and_embedding_df[\"embedding\"].tolist()),dtype=torch.float32).to(device)\n",
        "embeddings.shape"
      ],
      "metadata": {
        "id": "57PlKpzCScxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks_and_embedding_df.head()"
      ],
      "metadata": {
        "id": "fw4bsRBAScz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings[0]"
      ],
      "metadata": {
        "id": "WlGxoKe-Sc26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import util, SentenceTransformer\n",
        "\n",
        "embedding_model=SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\",\n",
        "                                    device=device) #choose the device to load the model to"
      ],
      "metadata": {
        "id": "avMINgCQSc5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the query\n",
        "#Note: This could be anything. But since we're working with a nutrition textbook, we'll stick with nutrition-based queries.\n",
        "query = \"macronutrients functions\"\n",
        "print(f\"Query:{query}\")\n",
        "\n",
        "#2. Embed the query to the same numerical space as the text examples\n",
        "#Note: Its important to embed your query with the same model you embedded your examples with.\n",
        "query_embedding = embedding_model.encode(query.convert_to_tensor=True)\n",
        "\n",
        "#3 get similarity scores with the dot product (we'll time this for fun )\n",
        "\n",
        "from time import perf_counter as timer\n",
        "\n",
        "start_time =timer()\n",
        "dot_scores=util.dot_score(a=query_embedding,b=embeddings)[0]\n",
        "end_time=timer()\n",
        "\n",
        "print(f\"time take to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
        "\n",
        "#4 Get the top-k results (we'll keep this to 5)\n",
        "top_results_dot_product=torch.topk(dot_scores,k=5)\n",
        "top_results_dot_product\n"
      ],
      "metadata": {
        "id": "m8Y9tejiSc80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "larger_embeddings = torch.randn(100*embeddings.shape[0], 768).to(device)\n",
        "print(f\"Embeddings shape: {larger_embeddings.shape}\")\n",
        "\n",
        "#perform dot product across 168000 embeddings\n",
        "start_time = timer()\n",
        "dot_scores=util.dot_score(a=query_embedding,b=larger_embeddings)[0]\n",
        "end_time = timer()\n",
        "print(f\"time take to get scores on {len(larger_embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")"
      ],
      "metadata": {
        "id": "FAS9tBWgKFXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define helper function to print wrapped text\n",
        "import textwrap\n",
        "\n",
        "def print_wrapped(text, wrap_length=80):\n",
        "  wrapped_text = textwrap.fill(text,wrap_length)\n",
        "  print(wrapped_text)"
      ],
      "metadata": {
        "id": "kQevJ5SUKFad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Query:'{query}'\\n\")\n",
        "print(\"Results\")\n",
        "#Loop through zipped together scores and indices from torch.topk\n",
        "for score, idx in zip(top_results_dot_product[0], top_results_dot_product[1]):\n",
        "   print(f\"score: {score:.4f}\")\n",
        "   #print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n",
        "   print(\"Text:\")\n",
        "   print_wrapped(pages_and_chunks[idx][\"sentence_chunk\"])\n",
        "   #print the page number too so we can reference the textbook further(and check the results)\n",
        "   print(f\"Page number: {pages and chunks[idx]['page_number']}\")\n",
        "   print(\"\\n\")"
      ],
      "metadata": {
        "id": "SKawcqyfKFcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "#Open PDF and load target page\n",
        "pdf_path = \"human-nutrition-text.pdf\"#requires PDF to be downloaded\n",
        "doc=fitz.open(pdf_path)\n",
        "page = doc.load_page(5 + 41) #number of page (our doc starts page numbers on page 41)\n",
        "\n",
        "#Get the image of the page\n",
        "img=page.get_pixmap(dpi=300)\n",
        "\n",
        "#Optional: save the image\n",
        "#ima.save(\"output_filename.png\")\n",
        "doc.close()\n",
        "\n",
        "#convert the Pixmap to a numpy array\n",
        "img_array = np.frombuffer(img.samples_mv,dtype=np.uint8).reshape((img.h,img.w,img.n))\n",
        "\n",
        "#Display the image using Matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(13,10))\n",
        "plt.imshow(img_array)\n",
        "plt.title(f\"Query: '{query}' | Most relevant page:\")\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "0JKKCnu3KFfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "def dot_product(vector1,vector2):\n",
        " return torch.dot(vector1,vector2)\n",
        "\n",
        "def cosine_similarity(vector1,vector2):\n",
        "  dot_product = torch.dot(vector1,vector2)\n",
        "  #Get Eucledian/L2 norm of each vector (remove the magnitude, keeps direction)\n",
        "  norm_vector1=torch.sqrt(torch.sum(vector1**2))\n",
        "  norm_vector2=torch.sqrt(torch.sum(vector2**2))\n",
        "\n",
        "  return dot_product / (norm_vector1 * norm_vector2)\n",
        "\n",
        "#Example tensors\n",
        "vector1=torch.tensor([1,2,3],dtype=torch.float32)\n",
        "vector2=torch.tensor([1,2,3],dtype=torch.float32)\n",
        "vector3=torch.tensor([4,5,6],dtype=torch.float32)\n",
        "vector4=torch.tensor([-1,-2,-3],dtype=torch.float32)\n",
        "\n",
        "#Calculate dot product\n",
        "print(\"Dot product between vector1 and vector2:\"), dot_product(vector1,vector2)\n",
        "print(\"Dot product between vector1 and vector3:\"), dot_product(vector1,vector3)\n",
        "print(\"Dot product between vector1 and vector4:\"), dot_product(vector1,vector4)\n",
        "\n",
        "#calculate cosine similarity\n",
        "print(\"Cosine similarity between vector1 and vector2:\"), cosine_similarity(vector1,vector2)\n",
        "print(\"Cosine similarity between vector1 and vector3:\"), cosine_similarity(vector1,vector3)\n",
        "print(\"Cosine similarity between vector1 and vector4:\"), cosine_similarity(vector1,vector4)\n",
        "\n"
      ],
      "metadata": {
        "id": "aeCqKfOgKFit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_relevant_resources(query: str,\n",
        "                                embeddings: torch.tensor,\n",
        "                                model: SentenceTransformer=embedding_model,\n",
        "                                n_resources_to_return: int=5,\n",
        "                                print_time: bool=true)\n",
        "\"\"\"\n",
        "Embeds a query with model and returns top k scores and indices from embeddings.\n",
        "\"\"\"\n",
        "#Embeds the query\n",
        "query_embedding = model.encode(query,convert_to_tensor=True)\n",
        "\n",
        "#Get dot product scores on embeddings\n",
        "start_time = timer()\n",
        "dot_scores = util.dot_score(query_embedding,embeddings)[0]\n",
        "end_time = timer()\n",
        "\n",
        "if print_time:\n",
        "  print(f\"[INFO] Time taken to get scores on {len(embeddings)} embeddings:{end_time-start_time:.5f} seconds.\")\n",
        "\n",
        "scores, indices = torch.topk(input=dot_scores,k=n_resources_to_return)\n",
        "\n",
        "return scores, indices\n",
        "def print_top_results_and_scores(query: str,embeddings: torch.tensor,pages_and_chunks:list[dict]=pages_and_chunks,n_resources_to_return: int=5):\n",
        "\n",
        "  \"\"\"\n",
        "  Takes a query, retrives most relevant resources\n",
        "   and prints them out descending order.\n",
        "   Note: Requires pages_and_chunks to be formatted in a specific way (see above for reference).\n",
        "   \"\"\"\n",
        "\n",
        "   scores,indices = retrieve_relevant_resources(query=query,embeddings=embeddings,n_resources_to_return=n_resources_to_return)\n",
        "\n",
        "   print(f\"Query: '{query}'\\n\")\n",
        "   print(\"Results\")\n",
        "   #Loop through zipped together scores and indicies\n",
        "   for score,index in zip(scores,indices):\n",
        "     print(f\"Score:{score.4f}\")\n",
        "     #Print relevant sentence chunk (since the scores are in descending order,\n",
        "     #the most relevant chunk will be first)\n",
        "     print_wrapped(pages_and_chunks[index][\"sentence_chunk\"])\n",
        "     #print the page number too so we can reference the textbook further and check the results\n",
        "     print(f\"page number:{pages_and_chunks[index]['page_number']}\")\n",
        "     print(\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T2rKM3Y4KFmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excellent Now let's test our fucntions out."
      ],
      "metadata": {
        "id": "zYQanQ2iqmbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"symptoms of pellagra\"\n",
        "#Get just the scores and indices of top related results\n",
        "scores, indices = retrieve_relevant_resources(query=query,embeddings=embeddings)\n",
        "\n",
        "scores,indices"
      ],
      "metadata": {
        "id": "7qv-MEUdKFpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print out the texts of the top scores\n",
        "print_top_results_and_scores(query=query,embeddings=embeddings)"
      ],
      "metadata": {
        "id": "2Y91AWYWKFrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get GPU available memory\n",
        "import torch\n",
        "gpu_memory_bytes = torch.cuda.get_device_properties(0).total_memory\n",
        "gpu_memory_gb=round(gpu_memory_bytes/(2**30))\n",
        "print(f\"Available GPU memory:{gpu_memory_gb} GB\")"
      ],
      "metadata": {
        "id": "ZfNDphKvKFvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Note: the following is Gemma focused, however, there are more and more LLMs of the 28 and 78 size appearing for local use.\n",
        "if gpu_memory_gb < 5.1:\n",
        "  print(f\"Your available GPU memory is {gpu_memory_gb}GB, you may not have enough memory to run a Gemma Locally without quatization.\")\n",
        "elif gpu_memory_gb < 8.1:\n",
        "  print(f\"GPU memory:{gpu_memory_gb} | Recommended model: Gemma 2B in 4-bit precision.\")\n",
        "  use_quantization_config=True\n",
        "  model_id=\"google/gemma-2b-it\"\n",
        "elif gpu_memory_gb < 19.0:\n",
        "  print(f\"GPU memory:{gpu_memory_gb} | Recommended model: Gemma 2B in float16 or Gemma 7B in 4-bit precision.\")\n",
        "  use_quantization_config=True\n",
        "  model_id=\"google/gemma-2b-it\"\n",
        "elif gpu_memory_gb > 19.0:\n",
        "  print(f\"GPU memory:{gpu_memory_gb} | Recommend model: Gemma 7B in 4-bit of float16 precision.\")\n",
        "  use_quatization_config = False\n",
        "  model_id=\"google/gemma-7b-it\"\n",
        "print(f\"use_quatization_config set to: {use_quatization_config}\")\n",
        "print(f\"model_id set to: {model_id}\")"
      ],
      "metadata": {
        "id": "W6aqBF_NubyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(token=\"\")"
      ],
      "metadata": {
        "id": "m3yyr5sAub00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers.utils import is_flash_attn_2_available\n",
        "\n",
        "from transformers import BitsAndBytesConfig\n",
        "quatization_config = BitsBytesConfig(load_in_4bit=True,bnb_4bit_compute_dtype=torch.float16)\n",
        "\n",
        "attn_implementation = 'sdpa'\n",
        "\n",
        "print(f\"[INFO] Using attention implementation:{attn_implementation}\")\n",
        "\n",
        "model_id=model_id\n",
        "print(f\"[INFO] Using model_id: {model_id}\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_id)\n",
        "\n",
        "llm_model=AutoModelForCausalLM.from_pretrained(pretrained_model_name_or_path=model_id,\n",
        "                                               torch_dtype=torch.float16,#datatype to use, we want float16\n",
        "                                               quantization_config=quatization_config if use_quatization_config else None,\n",
        "                                               low_cpu_mem_usage=False,#Use full memory\n",
        "                                               attn_implementation=attn_implementation)#which attention version to use\n",
        "\n",
        "\n",
        "if not use_quatization_config: #Quatization takes care fo device setting automatically, so if its not used , send model to Gpu\n",
        "  llm_model.to(device=\"cuda\")\n",
        "\n"
      ],
      "metadata": {
        "id": "nYk-Qi_vub3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_model"
      ],
      "metadata": {
        "id": "2LFp_a6Lub50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_num_params(model:torch.nn.module):\n",
        "  return sum([param.numel() for param in model.parameters()])\n",
        "get_model_num_params(llm_model)"
      ],
      "metadata": {
        "id": "X5QfOjenub81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_mem_size(model: torch.nn.Module):\n",
        "  \"\"\"\n",
        "   get how much memory a Pytorch model takes up.\n",
        "   \"\"\"\n",
        "   #Get model parameters and buffer sizes\n",
        "   mem_params=sum([param.nelement() * param.element_size() for param in model.parameters()])\n",
        "   mem_buffers = sum([buf.nelement() * buf.element_size() for buf in model.buffers()])\n",
        "\n",
        "   #calculate various model sizes\n",
        "   model_mem_bytes = mem_params + mem_buffers #in bytes\n",
        "   model_mem_mb=model_mem_bytes / (1024**2)# in megabytes\n",
        "   model_mem_gb = model_mem_bytes / (1024**3) # in gigabytes\n",
        "\n",
        "   return {\"model_mem_bytes\": model_mem_bytes,\n",
        "           \"model_mem_mb\":round(model_mem_mb,2),\n",
        "           \"model_mem_gb\":round(model_mem_gb,2)}\n",
        "\n",
        "get_model_mem_size(llm_model)"
      ],
      "metadata": {
        "id": "nDmPjLzBub_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text=\"What are the macronutrients, and what roles do they paly in the human body?\"\n",
        "print(f\"Input text:\\n{input_text}\")\n",
        "\n",
        "#create prompt template for instruction-tuned model\n",
        "dialogue_template=[\n",
        "    {\"role\":\"user\",\n",
        "     \"content\":input_text}\n",
        "]\n",
        "#Apply the chat template\n",
        "prompt=tokenizer.apply_chat_template(conversation=dialogue_template,\n",
        "                                     tokenize=False,#Keep as raw text(not tokenized)\n",
        "                                     add_generation_prompt=True)\n",
        "print(f\"\\nPrompt (formatted):\\n{prompt}\")"
      ],
      "metadata": {
        "id": "4-EwBPuSucB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "#Tokenize the input text (turn it into numbers) and send it to GPU\n",
        "input_ids = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "print(f\"Model input (tokenized):\\n{input_ids}\\n\")\n",
        "\n",
        "outputs=llm_model.generate(**input_ids,\n",
        "                           max_new_tokens=256) #define the maximum number of new tokens to create\n",
        "print(f\"Model output (tokens):\\n{outputs[0]}\\n\")"
      ],
      "metadata": {
        "id": "K2GQf8WcucFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decode the output tokens to text\n",
        "outputs_decoded = tokeizer.decode(outputs[0])\n",
        "print(f\"Model output (decoded):\\n{outputs_decoded}\\n\")"
      ],
      "metadata": {
        "id": "kVpbcFYJF0dD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Input text:{input_text}\\n\")\n",
        "print(f\"Output text:\\n{outputs_decoded.replace(prompt,'').replace('<bos>','').replace('<eos>','')}\")"
      ],
      "metadata": {
        "id": "d86CIV2lF0fd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#NUtrition-style questions generated with GPT4\n",
        "gpt4_questions=[\n",
        "    \"what are the macronutrients, and what roles do they play in the human body?\",\n",
        "    \"How do vitamins and minerals differ in their roles and importance for health?\",\n",
        "    \"Describe the process of digestion and absorption of nutrients in the human body.\",\n",
        "    \"What role does fibre play in digestion? Name five fibre conataining foods.\",\n",
        "    \"Explain the concept of energy balance and its importance in weight management.\"\n",
        "\n",
        "]\n",
        "\n",
        "#Manually craeted question list\n",
        "manual_questions=[\n",
        "    \"How often should infants be breastfed?\".\n",
        "    \"What are symptoms of pellagra?\",\n",
        "    \"How does salvia help with digestion?\",\n",
        "    \"What is the RDI for protein per day?\",\n",
        "    \"Water soluble vitamins\"]\n",
        "query_list = gpt4_questions + manual_questions"
      ],
      "metadata": {
        "id": "URJos4iGF0is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "query = random.choice(query_list)\n",
        "\n",
        "print(f\"Query: {query}\")\n",
        "\n",
        "#Get just scores and indices of top related results\n",
        "scores,indices = retrieve_relevant_resources(query=query,embeddings=embeddings)\n",
        "\n",
        "scores , indices"
      ],
      "metadata": {
        "id": "__AWJddmF0kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prompt_formatter(query: str,\n",
        "                     context_items: list[dict]) -> str:\n",
        "    \"\"\"\n",
        "    Augments query with text-based context from context_items.\n",
        "    \"\"\"\n",
        "    #join context items into one dotted paragraph\n",
        "    context = \"-\" + \"\\n-\".join([item[\"sentence_chunk\"] for item in context_items])\n",
        "\n",
        "    #create a base prompt with examples to help the model\n",
        "    #Note:This is very customizable,'ve chosen to use 3 examples of the answer style we'd like.\n",
        "\n",
        "\n",
        "\n",
        "   I\n",
        "    # We could also write this in a txt file and import it in if we wanted.\n",
        "    base_prompt = \"\"\"Based on the following context items, please answer the query.\n",
        "    Give yourself room to think by extracting relevant passages from the context before answering the query.\n",
        "    Don't return the thinking, only return the answer.\n",
        "    Make sure your answers are as explanatory as possible.\n",
        "    Use the following examples as reference for the ideal answer style.\n",
        "\n",
        "    Example 1:\n",
        "    Query: What are the fat-soluble vitamins?\n",
        "    Answer: The fat-soluble vitamins include Vitamin A, Vitamin D, Vitamin E, and Vitamin K. These vitamins are absorbed along with fats in the diet and are stored in the body's fatty tissues and liver. Because they can be stored for long periods, they do not need to be consumed every day.\n",
        "\n",
        "    Example 2:\n",
        "    Query: What are the causes of type 2 diabetes?\n",
        "    Answer: Type 2 diabetes is primarily caused by a combination of genetic and lifestyle factors. It is often associated with overnutrition and obesity, which can lead to insulin resistance—a condition where the body's cells do not respond effectively to insulin. Other major risk factors include a sedentary lifestyle and a family history of the disease.\n",
        "\n",
        "    Example 3:\n",
        "    Query: What is the importance of hydration for physical performance?\n",
        "    Answer: Hydration is crucial for physical performance because water plays key roles in maintaining blood volume, regulating body temperature through sweating, and lubricating joints. Proper hydration ensures that muscles receive oxygen, nutrients are transported efficiently, and it helps prevent fatigue, muscle cramps, and dizziness during exercise.\n",
        "\n",
        "    Now use the following context items to answer the user query:\n",
        "    Context: {context}\n",
        "    Relevant passages: <extract relevant passages from the context here>\n",
        "    User query: {query}\n",
        "    Answer:\"\"\"\n",
        "           #Update base prompt with context items and query\n",
        "           base_prompt=base_prompt.format(context=context,query=query)\n",
        "\n",
        "           #Create prompt template for instruction-tuned model\n",
        "           dialogue_template=[\n",
        "               {\"role\":\"user\",\n",
        "                \"content\":base_prompt}\n",
        "           ]\n",
        "\n",
        "           #Apply the chat template\n",
        "           prompt=tokenizer.apply_chat_template(conversation=dialogue_template,\n",
        "                                                tokenize=False,\n",
        "                                                add_generation_prompt=True)\n",
        "           return prompt"
      ],
      "metadata": {
        "id": "hmsMYjOzF0mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=random.choice(query_list)\n",
        "print(f\"Query:{query}\")\n",
        "\n",
        "#Get relevant resources\n",
        "scores,indices = retriev_relevant_resources(query=query,embeddings=embeddings)\n",
        "\n",
        "#Create a list of context items\n",
        "context_items=[pages_and_chunks[i] for i in indices]\n",
        "\n",
        "#Format prompt with context items\n",
        "prompt=prompt_formatter(query=query,context_items=context_items)\n",
        "\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "wT1qtgTSF0os"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "input_ids = tokenizer(prompt,return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "#generate an output of tokens\n",
        "outputs = llm_model.generate(**input_ids,temprature=0.7,do_sample=True,max_new_tokens=256)\n",
        "\n",
        "#Turn the output tokens into text\n",
        "output_text = tokenizer.decode(outputs[0])\n",
        "\n",
        "print(f\"Query: {query}\")\n",
        "print(f\"RAG answer:\\n{output_text.replace(prompt,'')}\")"
      ],
      "metadata": {
        "id": "fG6e6C16F0sG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask(query,temprature=0.7,max_new_tokens=512,format_answer_text=true,return_answer_only=True):\n",
        "  \"\"\"\n",
        "  Takes a query, finds relevant resources/context and generates an answer to the query based on the relevant resources.\n",
        "  \"\"\"\n",
        "  #Get just the scores and indices of top related results\n",
        "  scores,indices=retrieve_relevant_resources(query=query,embeddings=embeddings)\n",
        "\n",
        "  #Create a list of context items\n",
        "  context_items=[pages_and_chunks[i] for i in indices]\n",
        "\n",
        "  #Add score to context item\n",
        "  for i,item in enumerate(context_items):\n",
        "    item[\"score\"]=scores[i].cpu() #return score back to CPU\n",
        "\n",
        "  #Format the prompt with context items\n",
        "  prompt=prompt_formatter(query=query,context_items=context_items)\n",
        "  #Tokenize the prompt\n",
        "  input_ids=tokenizer(prompt,return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "  #Generate an output of tokens\n",
        "  outputs=llm_model.generate(**input_ids,temperature=temperature,do_sample=True,max_new_tokens=max_new_tokens)\n",
        "\n",
        "  #Turn the output tokens into text\n",
        "  output_text=tokenizer.decode(outputs[0])\n",
        "\n",
        "  if format_answer_text:\n",
        "    #Replace special tokens and unnecessary help message\n",
        "\n",
        "    output_text=output_text.replace(prompt,'').replace(\"<bos>\",\"\").replace(\"<eos>\",\"\").replace(\"Sure,here is the answer to the user query:\\n\\n\",\"\")\n",
        "  #only return the answer without the context items\n",
        "  if return_answer_only:\n",
        "    return output_text\n",
        "  return  output_text, context_items"
      ],
      "metadata": {
        "id": "hiJGuPKqjQI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=random.choice(query_list)\n",
        "print(f\"Query:{query}\")\n",
        "\n",
        "#Answer query with context and return context\n",
        "answer,context_items=ask(query=query,temperature=0.7,max_new_tokens=512,return_answer_only=False)\n",
        "\n",
        "print(f\"Answer:\\n\")\n",
        "print_wrapped(answer)\n",
        "print(f\"Context items:\")\n",
        "context_items"
      ],
      "metadata": {
        "id": "T3xcKpEmjQZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation of our results"
      ],
      "metadata": {
        "id": "VJukyN_ApX2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q rags datasets"
      ],
      "metadata": {
        "id": "RM9zYCcFjQcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Install required packages\n",
        "#!pip install raga datasets\n",
        "\n",
        "import pandas as pd\n",
        "from datasets import dataset\n",
        "from raga import evaluate\n",
        "from ragas.metrics import(\n",
        "    context_precision,\n",
        "    context_recall,\n",
        "    answer_relevancy,\n",
        "    faithfulness\n",
        ")\n",
        "\n",
        "#Try to import additional metrics if available\n",
        "try:\n",
        "   from raga.metrics import context_entity_recall\n",
        "except ImportError:\n",
        "  context_entity_recall = None\n",
        "  print(\"Context_entity_recall not available in this version\")\n",
        "\n",
        "try:\n",
        "  from raga.metrics import noise_robustness\n",
        "except ImportError:\n",
        "  noise_robustness = None\n",
        "  print(\"moise_robustness not available in this version\")"
      ],
      "metadata": {
        "id": "nj-Znf0QjQgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define evaluation question in this version\n",
        "\n",
        "eval_questions=[\n",
        "    \"How often should infants be breastfed?\",\n",
        "    \"What are symptoms of pellagra?\",\n",
        "    \"How does salvia help with digestion?\",\n",
        "    \"What is the RDI for protein per day, based on your weight?\",\n",
        "    \"What are micronutrients?\"\n",
        "]\n",
        "\n",
        "ground_truth_answers=[\n",
        "    \"Breastfeed infants on demand, about 8 to 12 times daily.\",\n",
        "    \"Pellagra's symptoms are dermatitis, diarrhea, dementia, and ultimately death.\",\n",
        "    \"Saliva uses enzymes to start breaking down fats and starches.\",\n",
        "    \"The RDI is 0.8 grams of protein per kilogram bodyweight.\",\n",
        "    \"Micronutrients are essential vitamins and minerals needed in small amounts.\"\n",
        "    ]"
      ],
      "metadata": {
        "id": "2f0zuc70qrnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_rag_answer(query):\n",
        "  \"\"\"Generate RAG answer for a given query\"\"\"\n",
        "  #Get relevant resources\n",
        "  scores,indices=retrieve_relevant_resources(query=query,embeddings=embeddings)\n",
        "\n",
        "  #Create a list of context items\n",
        "  context_items=[pages_and_chunks[i] for i in indices]"
      ],
      "metadata": {
        "id": "6YUW1_EJqrqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MEr5Q7Yuqrtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZGtLTlpeqrwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H4_T1Jm3qrzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_r-Hzzf9qr3G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}